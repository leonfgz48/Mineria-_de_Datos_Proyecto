{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7b6ca6-b75c-46ff-934e-65a6216ac925",
   "metadata": {},
   "source": [
    "# 1. Tratamiento de datos\n",
    "\n",
    "* Partiendo de las tablas tratadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "697729f0-f828-47c9-86e9-4088cff58709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Map Stuff\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2567ab18-9e74-4288-adf5-0bd6e560a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypth = \"/Users/cesarrojasflores/Documents/DataMining/moroccotopo/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e75e7a1-425f-4f34-b159-0ce14ade7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_outliers = pd.read_csv(mypth+\"variables_con_atípicos.csv\")\n",
    "wo_outliers = pd.read_csv(mypth+\"variables_sin_atípicos.csv\")\n",
    "categoric = pd.read_csv(mypth+\"variables_categoricas_airbnb.csv\")\n",
    "categoric_excel = pd.read_excel(mypth+\"variables_categoricas_airbnb.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7bcecf2-8782-4bdc-b80f-f95f1f5f25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "catvrs = categoric_excel.columns.to_list()\n",
    "numvrs = list(set(w_outliers.columns.to_list()) - set(catvrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ac92c46-bce3-4d53-9934-4222313815ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif catvrs == catvrs1:\\n    print(\"Las listas son iguales\")\\nelse:\\n    print(\"Las listas son diferentes\")\\n\\nprint(len(catvrs))\\nprint(len(catvrs1))\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "catvrs1 = categoric.columns.to_list()\n",
    "if catvrs == catvrs1:\n",
    "    print(\"Las listas son iguales\")\n",
    "else:\n",
    "    print(\"Las listas son diferentes\")\n",
    "\n",
    "print(len(catvrs))\n",
    "print(len(catvrs1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d5e0a64-e8f1-4cff-986b-332804bc2c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9625c02070a7420dac98c40f552db6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73194cff2a66446fa3c819c1712beaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab812494e1c04c26990c7e31296340cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6462c1e8ac2472688f721afbf374d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(w_outliers[numvrs].copy(), minimal=True)\n",
    "profile.to_file(\"Arbnb_EDA_num.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88b065a9-400a-4002-9947-b1e1412aca23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10017, 58)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a395fd5-e7d4-4ea2-8cb2-6c89c83070e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9150, 58)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7090f9d8-07f6-414d-b070-7664111676db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26536, 46)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_excel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305b1ce-11ce-4bc6-ac6f-9af254fc08cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(\n",
    "    df, title=\"Titanic Dataset\", html={\"style\": {\"full_width\": True}}, sort=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec07b9-832f-4073-ab21-d1a6577bc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_widgets()\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75512787-9dff-4252-9a44-0de63fe6ea10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380e8a0-95fe-4d2c-8801-9154ddf5fb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f45d42-97ff-471f-a785-928b04537ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec6e4c-1281-4b86-8e61-308992e6068c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce05a4-e3bd-43e0-a3e1-4c04080d3d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f475c-e516-4f8f-9b8c-17b6d0228308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c2bee-1474-4673-a063-dc78f906761d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ead47e7f-1218-41cb-8047-1df785f74d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.11.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<1.14,>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (1.13.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (2.2.2)\n",
      "Requirement already satisfied: matplotlib<3.10,>=3.5 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (3.8.4)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (2.5.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (3.1.4)\n",
      "Collecting visions<0.7.7,>=0.7.5 (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling)\n",
      "  Downloading visions-0.7.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.2,>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (1.26.4)\n",
      "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
      "  Downloading phik-0.12.4-cp312-cp312-macosx_10_13_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (2.32.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (4.66.4)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (0.13.2)\n",
      "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
      "  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (0.14.2)\n",
      "Collecting typeguard<5,>=3 (from ydata-profiling)\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting wordcloud>=1.9.3 (from ydata-profiling)\n",
      "  Downloading wordcloud-1.9.3-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting dacite>=1.8 (from ydata-profiling)\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numba<1,>=0.56.0 in /opt/anaconda3/lib/python3.12/site-packages (from ydata-profiling) (0.59.1)\n",
      "Requirement already satisfied: PyWavelets in /opt/anaconda3/lib/python3.12/site-packages (from imagehash==4.3.1->ydata-profiling) (1.5.0)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from imagehash==4.3.1->ydata-profiling) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba<1,>=0.56.0->ydata-profiling) (0.42.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2024.8.30)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.6)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/anaconda3/lib/python3.12/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.2.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
      "Downloading ydata_profiling-4.11.0-py2.py3-none-any.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.0/390.0 kB\u001b[0m \u001b[31m568.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m427.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Downloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
      "Downloading phik-0.12.4-cp312-cp312-macosx_10_13_x86_64.whl (659 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.0/659.0 kB\u001b[0m \u001b[31m335.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading visions-0.7.6-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m574.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wordcloud-1.9.3-cp312-cp312-macosx_10_9_x86_64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m648.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27080 sha256=aadfa3887cc4520aeacddf642d8611d46d09354372d460c258893f7ffa41daab\n",
      "  Stored in directory: /Users/cesarrojasflores/Library/Caches/pip/wheels/5f/d4/d7/4189b07b5902ee9f3ce0dbb14909fbe8037c39d6c63ffd49c9\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, typeguard, multimethod, dacite, imagehash, wordcloud, visions, phik, ydata-profiling\n",
      "Successfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.12 phik-0.12.4 typeguard-4.3.0 visions-0.7.6 wordcloud-1.9.3 ydata-profiling-4.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02de9160-9d05-4a49-a452-c8d95b8a0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlemaps\n",
      "  Downloading googlemaps-4.10.0.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from googlemaps) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2024.8.30)\n",
      "Building wheels for collected packages: googlemaps\n",
      "  Building wheel for googlemaps (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googlemaps: filename=googlemaps-4.10.0-py3-none-any.whl size=40712 sha256=24cd53cd4bde4287c9ca24cc57e943a9bb26a6731755d45cb2b5210e7b4183ee\n",
      "  Stored in directory: /Users/cesarrojasflores/Library/Caches/pip/wheels/4c/6a/a7/bbc6f5c200032025ee655deb5e163ce8594fa05e67d973aad6\n",
      "Successfully built googlemaps\n",
      "Installing collected packages: googlemaps\n",
      "Successfully installed googlemaps-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1855e6-a096-4396-bd3a-d4b27f4a6b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m717.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m953.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a851751-35f7-4458-95f0-396e0b09501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"tu_archivo.csv\")\n",
    "\n",
    "# Selección de características de baja varianza\n",
    "selector = VarianceThreshold(threshold=0.1)  # Elimina características con varianza menor a 0.1\n",
    "df_reduced = selector.fit_transform(df)\n",
    "df_reduced = pd.DataFrame(df_reduced, columns=df.columns[selector.get_support()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc6c6d-b911-420e-b6a9-0e8ed244107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Transformación logarítmica (añadir 1 para evitar log(0))\n",
    "df['columna_transformada'] = np.log1p(df['columna_original'])\n",
    "\n",
    "# Escalado con StandardScaler (normalización Z-score)\n",
    "scaler = StandardScaler()\n",
    "df[['columna_normalizada']] = scaler.fit_transform(df[['columna_original']])\n",
    "\n",
    "# Escalado con MinMaxScaler (0 a 1)\n",
    "scaler = MinMaxScaler()\n",
    "df[['columna_minmax']] = scaler.fit_transform(df[['columna_original']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6330487-6030-4b7b-893d-33bf2524f360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752534a-5aa2-47b6-9b01-93b33cd5dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear un DataFrame de ejemplo con valores faltantes\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5, np.nan, 7, 8],\n",
    "    'feature2': [5, 6, np.nan, 8, 9, 10, 11, 12],\n",
    "    'feature3': [9, 10, 11, np.nan, 13, 14, 15, 16],\n",
    "    'target_column': [10, 20, 30, 40, np.nan, 60, 70, 80]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identificar las filas con y sin valores nulos en la columna objetivo\n",
    "df_missing = df[df['target_column'].isnull()]  # Filas con valores nulos en la columna objetivo\n",
    "df_not_missing = df.dropna(subset=['target_column'])  # Filas sin valores nulos en la columna objetivo\n",
    "\n",
    "# Separar características y el objetivo\n",
    "X = df_not_missing.drop(columns=['target_column'])\n",
    "y = df_not_missing['target_column']\n",
    "\n",
    "# Entrenar el modelo para imputación\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predecir los valores faltantes\n",
    "X_missing = df_missing.drop(columns=['target_column'])\n",
    "predicted_values = model.predict(X_missing)\n",
    "\n",
    "# Llenar los valores faltantes con las predicciones\n",
    "df.loc[df['target_column'].isnull(), 'target_column'] = predicted_values\n",
    "\n",
    "print(\"DataFrame después de la imputación con el modelo:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8672ebe-83d2-4b9a-aa8a-efc7df3e8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ejemplo de datos con valores nulos y columnas de baja varianza\n",
    "data = {\n",
    "    'A': [1, 2, 2, np.nan, 4, 5, 5, 5],\n",
    "    'B': [np.nan, 3, 3, 3, np.nan, 3, 3, 3],\n",
    "    'C': [1, 1, 1, 1, 1, 1, 1, 1],  # Columna de baja varianza\n",
    "    'D': [1, np.nan, 3, 4, 5, np.nan, 7, 8],\n",
    "    'E': [3, 3, np.nan, np.nan, 6, 6, 6, 6]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "### 1. Selección de Variables ###\n",
    "\n",
    "# Selección por varianza (eliminar columnas de baja varianza)\n",
    "selector = VarianceThreshold(threshold=0.1)  # Umbral de varianza\n",
    "df_high_variance = pd.DataFrame(selector.fit_transform(df), columns=df.columns[selector.get_support()])\n",
    "print(\"DataFrame después de eliminar columnas de baja varianza:\\n\", df_high_variance)\n",
    "\n",
    "# Selección por correlación (eliminar columnas altamente correlacionadas)\n",
    "correlation_matrix = df_high_variance.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Encontrar columnas con alta correlación (ejemplo: umbral de 0.9)\n",
    "high_correlation_cols = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "df_no_high_corr = df_high_variance.drop(columns=high_correlation_cols)\n",
    "print(\"\\nDataFrame después de eliminar columnas altamente correlacionadas:\\n\", df_no_high_corr)\n",
    "\n",
    "### 2. Imputación de Valores Faltantes ###\n",
    "\n",
    "# Imputación básica con la media, mediana o moda\n",
    "# Imputación de la media para valores numéricos\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df_mean_imputed = pd.DataFrame(imputer_mean.fit_transform(df_no_high_corr), columns=df_no_high_corr.columns)\n",
    "print(\"\\nDataFrame después de la imputación con la media:\\n\", df_mean_imputed)\n",
    "\n",
    "# Imputación de la mediana para valores numéricos\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "df_median_imputed = pd.DataFrame(imputer_median.fit_transform(df_no_high_corr), columns=df_no_high_corr.columns)\n",
    "print(\"\\nDataFrame después de la imputación con la mediana:\\n\", df_median_imputed)\n",
    "\n",
    "# Imputación de la moda para valores categóricos (si hubiera)\n",
    "imputer_mode = SimpleImputer(strategy='most_frequent')\n",
    "df_mode_imputed = pd.DataFrame(imputer_mode.fit_transform(df_no_high_corr), columns=df_no_high_corr.columns)\n",
    "print(\"\\nDataFrame después de la imputación con la moda:\\n\", df_mode_imputed)\n",
    "\n",
    "# Imputación avanzada usando KNN (K-Nearest Neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_no_high_corr), columns=df_no_high_corr.columns)\n",
    "print(\"\\nDataFrame después de la imputación con KNN:\\n\", df_knn_imputed)\n",
    "\n",
    "### 3. Tratamiento de Valores Nulos ###\n",
    "\n",
    "# Detectar columnas con un alto porcentaje de valores nulos (umbral de 50%)\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "high_missing_cols = missing_percentage[missing_percentage > 50].index\n",
    "df_dropped_missing = df.drop(columns=high_missing_cols)\n",
    "print(\"\\nDataFrame después de eliminar columnas con más del 50% de valores nulos:\\n\", df_dropped_missing)\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df_dropped_rows = df.dropna()\n",
    "print(\"\\nDataFrame después de eliminar filas con valores nulos:\\n\", df_dropped_rows)\n",
    "\n",
    "# Rellenar valores nulos con valores constantes (ejemplo: 0 para columnas numéricas)\n",
    "df_filled_constant = df.fillna(0)\n",
    "print(\"\\nDataFrame después de rellenar valores nulos con un valor constante (0):\\n\", df_filled_constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f10529-0c29-4d01-bb87-bf17b8e88db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Transformación logarítmica (añadir 1 para evitar log(0))\n",
    "df['columna_transformada'] = np.log1p(df['columna_original'])\n",
    "\n",
    "# Escalado con StandardScaler (normalización Z-score)\n",
    "scaler = StandardScaler()\n",
    "df[['columna_normalizada']] = scaler.fit_transform(df[['columna_original']])\n",
    "\n",
    "# Escalado con MinMaxScaler (0 a 1)\n",
    "scaler = MinMaxScaler()\n",
    "df[['columna_minmax']] = scaler.fit_transform(df[['columna_original']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed563e-b61d-4241-9cbc-34860c624660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columna a partir de la suma de dos columnas\n",
    "df['nueva_columna'] = df['columna1'] + df['columna2']\n",
    "\n",
    "# Crear variables temporales (día, mes, año) de una columna de fechas\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['dia'] = df['fecha'].dt.day\n",
    "df['año'] = df['fecha'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7aa7df-8043-421e-b257-f63121e48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputación de la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['columna']] = imputer.fit_transform(df[['columna']])\n",
    "\n",
    "# Crear columna de indicador de valores faltantes\n",
    "df['columna_faltante'] = df['columna'].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf0f05-8172-4c92-93a3-63bdef71bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "# Sample data\n",
    "categories = ['Metric 1', 'Metric 2', 'Metric 3', 'Metric 4', 'Metric 5']\n",
    "values = [4, 3, 2, 5, 4]\n",
    "values += values[:1]  # Circular data to connect the last point to the first\n",
    "\n",
    "# Radar chart setup\n",
    "N = len(categories)\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "plt.xticks(angles[:-1], categories)\n",
    "ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    "ax.fill(angles, values, color='b', alpha=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f30ddf-33ed-4376-98c9-d74e6933e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = np.random.rand(10, 10)  # Generate a 10x10 matrix with random values\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c375266-cbb5-45db-92f2-8116f43491ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the geocoder\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# Example coordinates for Mexico City\n",
    "latitude = 19.4326\n",
    "longitude = -99.1332\n",
    "\n",
    "# Perform reverse geocoding\n",
    "location = geolocator.reverse((latitude, longitude), language=\"es\")\n",
    "\n",
    "# Extract the postal code\n",
    "if location and 'postcode' in location.raw['address']:\n",
    "    postal_code = location.raw['address']['postcode']\n",
    "    print(\"Código Postal:\", postal_code)\n",
    "else:\n",
    "    print(\"No se encontró código postal para estas coordenadas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
